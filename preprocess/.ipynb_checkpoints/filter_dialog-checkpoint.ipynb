{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import ipdb\n",
    "import json\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from collections import defaultdict\n",
    "import ipdb\n",
    "from itertools import chain\n",
    "\n",
    "'''\n",
    "    UTILITIES\n",
    "'''\n",
    "\n",
    "forbidden_verbs = ['said']\n",
    "\n",
    "def convertTime(value):\n",
    "    second = value%60\n",
    "    minute = int(value/60)%60\n",
    "    hour = int(value/3600)\n",
    "    return '{}:{:02}:{:02}'.format(hour, minute, second)\n",
    "\n",
    "def getBookName(filen):\n",
    "    filen.split('/')[-1]\n",
    "    book_path = '{}/books/'.format(bksnmvs_path)\n",
    "    book_name = filen+'.(hl-2).mat'\n",
    "    return book_path+book_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    PATHS AND NAMES\n",
    "'''\n",
    "\n",
    "dataset_path = '/data/vision/torralba/datasets/movies/data/'\n",
    "bksnmvs_path = '/data/vision/torralba/frames/data_acquisition/booksmovies/data/booksandmovies/'\n",
    "anno_path = '{}/antonio/annotation/'.format(bksnmvs_path)\n",
    "text_annotation_path = '/data/vision/torralba/movies-books/booksandmovies/joanna/bksnmovies/data/gt_alignment/consecutive_text_labels_v2'\n",
    "labeled_sents = json.load(open('../data/bksnmovies/labeled_sents.json', 'r'))\n",
    "movies = ['American.Psycho','Brokeback.Mountain','Fight.Club','Gone.Girl','Harry.Potter.and.the.Sorcerers.Stone','No.Country.for.Old.Men','One.Flew.Over.the.Cuckoo.Nest','Shawshank.Redemption','The.Firm','The.Green.Mile','The.Road']\n",
    "movies_titles = [movie.replace('.', '_') for movie in movies]\n",
    "imbds = ['tt0144084','tt0388795','tt0137523','tt2267998','tt0241527','tt0477348','tt0073486','tt0111161','tt0106918','tt0120689','tt0898367']\n",
    "dataset_split = 1 # 1 for 90% data from all movies in train and 10% in val; 2 for n-1 movies in train 1 in val\n",
    "val_movie = movies[0]\n",
    "\n",
    "labeled_sents = json.load(open('../data/bksnmovies/labeled_sents.json', 'r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gone.Girl\n",
      "420: This place is a bit of a hole in the wall,.\n",
      "421: But we had a great kiss there one Tuesday last fall.\n",
      "422: Ever been in a spelling bee as a kid?\n",
      "423: That snowy second after the announcement of the word as you sift your brain to see if you can spell it?\n",
      "424: It was like that, the blank panic.\n",
      "425: \"An Irish bar in a not-so-Irish place,\" Amy nudged.\n",
      "426: I bit the side of my lip, started a shrug, scanning our living room as if the answer might appear.\n",
      "427: She gave me another very long minute.\n",
      "428: \"We were lost in the rain,\" she said in a voice that was pleading on the way to peeved.\n",
      "429: I finished the shrug.\n",
      "430: \"McMann's, Nick.\n",
      "431: Remember, when we got lost in the rain in Chinatown trying to find that dim sum place, and it was supposed to be near the statue of Confucius but it turns out there are two statues of Confucius, and we ended up at that random Irish bar all soaking wet, and we slammed a few whiskeys, and you grabbed me and kissed me, and it was\u0014\"\"Right!\n",
      "432: You should have done a clue with Confucius, I would have gotten that.\"\n",
      "433: \"The statue wasn't the point.\n",
      "434: The place was the point.\n",
      "435: The moment.\n",
      "436: I just thought it was special.\"\n",
      "437: She said these last words in a childish lilt that I once found fetching.\n",
      "438: \"It was special.\"\n",
      "439: I pulled her to me and kissed her.\n",
      "440: \"That smooch right there was my special anniversary reenactment.\n",
      "441: Let's go do it again at McMann's.\"\n",
      "442: At McMann's, the bartender, a big, bearded bear-kid, saw us come in and grinned, poured us both whiskeys, and pushed over the next clue.\n",
      "443: When I'm down and feeling blue There's only one place that will do.\n",
      "444: That one turned out to be the Alice in.\n",
      "445: Wonderland statue at Central Park, which Amy had told me - she'd told me, she knew she'd told me many times - lightened her moods as a child.\n",
      "446: I do not remember any of those conversations.\n",
      "447: I'm being honest here, I just don't.\n",
      "448: I have a dash of ADD, and I've always found my wife a bit dazzling, in the purest sense of the word: to lose clear vision, especially from looking at bright light.\n",
      "449: It was enough to be near her and hear her talk, it didn't always matter what she was saying.\n",
      "450: It should have, but it didn't.\n",
      "451: By the time we got to the end of the day, to exchanging our actual presents - the traditional paper presents for the first year of marriage - Amy was not speaking to me.\n",
      "452: \"I love you, Amy.\n",
      "453: You know I love you,\" I said, tailing her in and out of the family packs of dazed tourists parked in the middle of the sidewalk, oblivious and openmouthed.\n",
      "454: Amy was slipping through the Central Park crowds, maneuvering between laser-eyed joggers and scissor-legged skaters, kneeling parents and toddlers careering like drunks, always just ahead of me, tight- lipped, hurrying nowhere.\n",
      "455: Me trying to catch up, grab her arm.\n",
      "456: She stopped finally, gave me a face unmoved as I explained myself, one mental finger tamping down my exasperation: \"Amy, I don't get why I need to prove my love to you by remembering the exact same things you do, the exact same way you do.\n",
      "457: It doesn't mean I don't love our life together.\"\n",
      "458: A nearby clown blew up a balloon animal, a man bought a rose, a child licked an ice cream cone, and a genuine tradition was born, one I'd never forget: Amy always going overboard, me never, ever worthy of the effort.\n",
      "459: Happy anniversary, asshole.\n",
      "460: \"I'm guessing -five years - she's going to get really pissed,\" Go continued.\n",
      "461: \"So I hope you got her a really good present.\"\n",
      "462: \"On the to-do list.\"\n",
      "463: \"What's the, like, symbol, for five years?\n",
      "464: Paper?\"\n",
      "465: \"Paper is first year,\" I said.\n",
      "466: At the end of Year One's unexpectedly wrenching treasure hunt, Amy presented me with a set of posh stationery, my initials embossed at the top, the paper so creamy I expected my fingers to come away moist.\n",
      "467: In return, I'd presented my wife with a bright red dime-store paper kite, picturing the park, picnics, warm summer gusts.\n",
      "468: Neither of us liked our presents; we'd each have preferred the other's.\n",
      "469: It was a reverse O. Henry.\n",
      "470: 'Silver?'\n",
      "471: guessed Go.\n",
      "472: 'Bronze?\n",
      "473: Scrimshaw?\n",
      "474: Help me out.'\n",
      "475: 'Wood,' I said.\n",
      "476: 'There's no romantic present for wood.'\n",
      "477: At the other end of the bar, Sue neatly folded her newspaper and left it on the bartop with her empty mug and a five-dollar bill.\n",
      "478: We all exchanged silent smiles as she walked out.'\n",
      "479: I got it,' Go said.\n",
      "480: 'Go home, fuck her brains out, then smack her with your penis and scream, \u001c",
      " There's some wood for you, bitch!\n",
      "481: We laughed.\n",
      "482: Then we both flushed pink in our cheeks in the same spot.\n",
      "483: It was the kind of raunchy, unsisterly joke that Go enjoyed tossing at me like a grenade.\n",
      "484: It was also the reason why, in high school, there were always rumors that we secretly screwed.\n",
      "485: Twincest.\n",
      "486: We were too tight: our inside jokes, our edge-of-the-party whispers.\n",
      "487: I'm pretty sure I don't need to say this, but you are not Go, you might misconstrue, so I will: My sister and I have never screwed or even thought of screwing.\n",
      "488: We just really like each other.\n",
      "489: Go was now pantomiming dick- slapping my wife.\n",
      "490: No, Amy and Go were never going to be friends.\n",
      "491: They were each too territorial.\n",
      "492: Go was used to being the alpha girl in my life, Amy was used to being the alpha girl in everyone's life.\n",
      "493: For two people who lived in the same city - the same city twice: first New York, now here - they barely knew each other.\n",
      "494: They flitted in and out of my life like well-timed stage actors, one going out the door as the other came in, and on the rare occasions when they both inhabited the same room, they seemed somewhat bemused at the situation.\n",
      "495: Before Amy and I got serious, got engaged, got married, I would get glimpses of Go's thoughts in a sentence here or there.\n",
      "496: It's funny, I can't quite get a bead on her, like who she really is.\n",
      "497: And: You just seem kind of not yourself with her.\n",
      "498: And: There's a difference between really loving someone and loving the idea of her.\n",
      "499: And finally: The important thing is she makes you really happy.\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "movie =movies[i]\n",
    "print(movie)\n",
    "\n",
    "title = movies_titles[i]\n",
    "imbd = imbds[i]\n",
    "\n",
    "labels = labeled_sents[movie]\n",
    "### SCENE AND SHOTS\n",
    "\n",
    "# Load shot info\n",
    "srt = scipy.io.loadmat('{}srts/{}.mat'.format(bksnmvs_path, movie))\n",
    "\n",
    "\n",
    "### GT DATAFRAME\n",
    "\n",
    "# Load book\n",
    "book_name = getBookName(movie)\n",
    "book_file = scipy.io.loadmat(book_name)\n",
    "sentences = book_file['book']['sentences'].item()['sentence']\n",
    "for i in range(420, 500):\n",
    "    print(f\"{i}: {sentences[i][0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'I been settin here all day.'\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repr(sentences[420][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isVisualDialog(labels):\n",
    "    is_dialog = False\n",
    "    is_visual = False\n",
    "    for label in labels:\n",
    "        if 'dialog' in label: is_dialog = True\n",
    "        if 'description' in label: is_visual = True\n",
    "    if is_visual and is_dialog: return ['dialog', 'visual']\n",
    "    else: return ['dialog']\n",
    "\n",
    "def isVisual(labels):\n",
    "    is_visual = False\n",
    "    for label in labels:\n",
    "        if 'description' in label: is_visual = True\n",
    "    if is_visual: return ['visual']\n",
    "    else: return ['non-visual']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground-truth annotations\n",
    "dialog_anno = {}\n",
    "i = 7\n",
    "movie = movies[i]\n",
    "print('Getting ground-truth for movie: ' + movie)\n",
    "\n",
    "title = movies_titles[i]\n",
    "imbd = imbds[i]\n",
    "\n",
    "labels = labeled_sents[movie]\n",
    "### SCENE AND SHOTS\n",
    "\n",
    "# Load shot info\n",
    "srt = scipy.io.loadmat('{}srts/{}.mat'.format(bksnmvs_path, movie))\n",
    "\n",
    "\n",
    "### GT DATAFRAME\n",
    "\n",
    "# Load book\n",
    "book_name = getBookName(movie)\n",
    "book_file = scipy.io.loadmat(book_name)\n",
    "\n",
    "dialog_anno[movie] = {}\n",
    "\n",
    "# Filter out dialogs\n",
    "sentences = book_file['book']['sentences'].item()['sentence']\n",
    "is_dialog = False\n",
    "for j, sentence in enumerate(sentences):\n",
    "    count = sentence[0][0].count('\"')\n",
    "    labels = labeled_sents[movie][str(j)]\n",
    "    if count%2 == 1:\n",
    "        if is_dialog: is_dialog = False\n",
    "        else: is_dialog = True\n",
    "        dialog_anno[movie][j] = isVisualDialog(labels)\n",
    "    elif count == 0:\n",
    "        if is_dialog: dialog_anno[movie][j] = isVisualDialog(labels)\n",
    "        else:\n",
    "            dialog_anno[movie][j] = isVisual(labels)\n",
    "    else:\n",
    "        is_dialog = False\n",
    "        dialog_anno[movie][j] = isVisualDialog(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(100,200):\n",
    "    print(f\"{sentences[j][0][0]}: {dialog_anno[movie][j]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
